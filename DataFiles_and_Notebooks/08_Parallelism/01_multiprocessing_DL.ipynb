{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ../00_AdvancedPythonConcepts/talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/l/AUV1r1xvhBdPF6lX-2SJLkO-vkkmCXEDrMwB/image.png\">\n",
    "http://www.slideshare.net/ManojitNandi/parallel-programming-in-python-speeding-up-your-analysis\n",
    "\n",
    "Remember, you can create (fork) many processes, which are copies of the original parent process (memory, data, state) and act independently of each other. To share data between them you have to explicitly do that within each process. The Pythonic way we do multiprocessing (creation of new processes, communication between processes) is with `multiprocessing`.\n",
    "\n",
    "*\"effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows.\"*\n",
    "\n",
    "- https://docs.python.org/3/library/multiprocessing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analog to `threading.Thread` is `multiprocessing.Process`. You should be able to do a drop-in replacement. Instead of `current_thread()` you'd use `os.getpid()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snakeviz\n",
      "  Downloading snakeviz-0.4.1-py2.py3-none-any.whl (166kB)\n",
      "\u001b[K    100% |████████████████████████████████| 174kB 1.7MB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): tornado>=2.0 in /Users/dlurie/anaconda/envs/py35/lib/python3.5/site-packages (from snakeviz)\n",
      "Installing collected packages: snakeviz\n",
      "Successfully installed snakeviz-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(MainThread) worker: 0 sleeping for 4 s, name: 7354\n",
      "(MainThread) worker: 1 sleeping for 2 s, name: 7355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file '/var/folders/s1/gv4yr2493jq4d4jtzpvhp0z00000gn/T/tmpnjvgop7m'. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(MainThread) done\n",
      "(MainThread) done\n"
     ]
    }
   ],
   "source": [
    "%%snakeviz\n",
    "\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='(%(threadName)-9s) %(message)s',)\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "def worker(num):\n",
    "    \"\"\"thread worker function\"\"\"\n",
    "    \n",
    "    sleep_time = random.randint(1,5)\n",
    "    logging.debug('worker: {0} sleeping for {1} s, name: {2}'\n",
    "                   .format(num,sleep_time,os.getpid()))\n",
    "    time.sleep(sleep_time)\n",
    "    logging.debug('done')\n",
    "    return\n",
    "\n",
    "procs = []\n",
    "for i in range(2):\n",
    "    p = multiprocessing.Process(target=worker, args=(i,))\n",
    "    procs.append(p)\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your machine has multiple cores, these two processes may get run on those two separate cores, independently.\n",
    "\n",
    "You may need to share info between processes. You can do this, just like with Threads with `Queues`. You can also use the (UNIX-like) Pipe to have  two processes communicate with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "# https://docs.python.org/3/library/multiprocessing.html#exchanging-objects-between-processes\n",
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=f, args=(child_conn,))\n",
    "    p.start()\n",
    "    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pools of workers (in separate processes) with multiprocessing Pool.\n",
    "\n",
    "https://docs.python.org/3.5/library/multiprocessing.html#using-a-pool-of-workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool \n",
    "pool = Pool(processes=4)     # start 4 worker processes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.Pool at 0x104ac6320>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def g(x): \n",
    "    time.sleep(0.2)\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 ms, sys: 1.5 ms, total: 3.94 ms\n",
      "Wall time: 2.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time list(map(g,range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 ms, sys: 1.55 ms, total: 3.65 ms\n",
      "Wall time: 603 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pool.map(g,range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1 9 0 49 36 25 16 81 64 "
     ]
    }
   ],
   "source": [
    "# print same numbers in arbitrary order\n",
    "for i in pool.imap_unordered(g, range(10)):\n",
    "    print(i,sep=\" \",end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is packaging (pickling) up your functions and sending them to different processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x104bce840>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ea45574c21dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/dlurie/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlurie/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlurie/anaconda/envs/py35/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    383\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlurie/anaconda/envs/py35/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlurie/anaconda/envs/py35/lib/python3.5/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x104bce840>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "pool.map(lambda x: x**3, range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# run only one process \"g(10)\" asynchronously \n",
    "result = pool.apply_async(g, [10])\n",
    "\n",
    "# prints \"100\" unless you timeout\n",
    "print(result.get(timeout=0.4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 *****\n",
      "0.0474 sec\n",
      "2 *****\n",
      "0.0408 sec\n",
      "3 *****\n",
      "0.0494 sec\n",
      "4 *****\n",
      "0.0374 sec\n",
      "8 *****\n",
      "0.0523 sec\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool \n",
    "import time\n",
    "\n",
    "def f(x): \n",
    "    return x*x\n",
    "\n",
    "for i in [1,2,3,4,8]:\n",
    "    print(i,\"*\"*5,flush=True)\n",
    "    pool = Pool(processes=i)               # start 4 worker processes \n",
    "    start = time.time()\n",
    "    pool.map(f, range(100000))\n",
    "    print(\"{0:0.4f} sec\".format(time.time() - start))\n",
    "    pool.terminate()\n",
    "    del pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core file size          (blocks, -c) 0\r\n",
      "data seg size           (kbytes, -d) unlimited\r\n",
      "file size               (blocks, -f) unlimited\r\n",
      "max locked memory       (kbytes, -l) unlimited\r\n",
      "max memory size         (kbytes, -m) unlimited\r\n",
      "open files                      (-n) 4864\r\n",
      "pipe size            (512 bytes, -p) 1\r\n",
      "stack size              (kbytes, -s) 8192\r\n",
      "cpu time               (seconds, -t) unlimited\r\n",
      "max user processes              (-u) 709\r\n",
      "virtual memory          (kbytes, -v) unlimited\r\n"
     ]
    }
   ],
   "source": [
    "!ulimit -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `concurrent.futures` - Launching parallel tasks\n",
    "\n",
    "Built-in, create different pools for executing **maps** (single loop over data). Local resources.\n",
    "\n",
    "`The concurrent.futures module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "The asynchronous execution can be performed with threads, using ThreadPoolExecutor, or separate processes, using ProcessPoolExecutor. Both implement the same interface, which is defined by the abstract Executor class.`\n",
    "\n",
    "https://docs.python.org/3/library/concurrent.futures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor()  # can also use a threadpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.64 ms, sys: 3.74 ms, total: 12.4 ms\n",
      "Wall time: 8.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from time import sleep\n",
    "\n",
    "results = []\n",
    "for i in range(8):\n",
    "    sleep(1)\n",
    "    results.append(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 14.7 ms, total: 25.9 ms\n",
      "Wall time: 2.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from time import sleep\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor() \n",
    "\n",
    "def slowfunc(x):\n",
    "    sleep(1)\n",
    "    return(x+1)\n",
    "\n",
    "results = list(e.map(slowfunc,range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figured out I have 4 cores and ran it in 4 separate processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout\n",
    "\n",
    "Convert the sequential code to parallel using `concurrent.futures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
    "\n",
    "def titlebot(x):\n",
    "    url = \"https://en.wikipedia.org/wiki/Special:Random\"\n",
    "    a = requests.get(url)\n",
    "    resp = a.text\n",
    "    print(\"title=\",BeautifulSoup(resp, 'html.parser')\n",
    "          .title.string.split(\"- Wikipedia\")[0],\"len=\",len(resp))\n",
    "    return(len(resp))\n",
    "\n",
    "e = ThreadPoolExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Thread-36) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-26) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-30) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-29) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-31) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-27) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-32) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-33) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-34) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-35) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-28) Starting new HTTPS connection (1): en.wikipedia.org\n",
      "(Thread-33) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-35) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-36) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-34) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-32) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-27) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-29) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-28) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-35) \"GET /wiki/Dasgupta HTTP/1.1\" 200 9968\n",
      "(Thread-34) \"GET /wiki/Telephone_numbers_in_Andorra HTTP/1.1\" 200 9800\n",
      "(Thread-32) \"GET /wiki/Navia_immersa HTTP/1.1\" 200 7872\n",
      "(Thread-28) \"GET /wiki/Mianzulan HTTP/1.1\" 200 14106\n",
      "(Thread-30) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-26) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-31) \"GET /wiki/Special:Random HTTP/1.1\" 302 20\n",
      "(Thread-29) \"GET /wiki/Ungheni,_Arge%C8%99 HTTP/1.1\" 200 12225\n",
      "(Thread-30) \"GET /wiki/One_Small_Step_(album) HTTP/1.1\" 200 9565\n",
      "(Thread-33) \"GET /wiki/Meinl_(surname) HTTP/1.1\" 200 7054\n",
      "(Thread-36) \"GET /wiki/XHACB-FM HTTP/1.1\" 200 11339\n",
      "(Thread-31) \"GET /wiki/Iridomyrmex_mattiroloi HTTP/1.1\" 200 8613\n",
      "(Thread-27) \"GET /wiki/Septaria_(gastropod) HTTP/1.1\" 200 9541\n",
      "(Thread-26) \"GET /wiki/List_of_Royal_Artillery_Batteries HTTP/1.1\" 200 15455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title= Dasgupta  len= 34263\n",
      "title= Navia immersa  len= 27197\n",
      "title= Telephone numbers in Andorra  len= 39549\n",
      "title= Meinl (surname)  len= 23353\n",
      "title= One Small Step (album)  len= 34918\n",
      "title= Ungheni, Argeș  len= 46284\n",
      "title= Iridomyrmex mattiroloi  len= 29442\n",
      "title= XHACB-FM  len= 44710\n",
      "title= Mianzulan  len= 63028\n",
      "title= Septaria (gastropod)  len= 34478\n",
      "title= List of Royal Artillery Batteries  len= 69138\n"
     ]
    }
   ],
   "source": [
    "results = list(e.map(titlebot,range(11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69138, 34478, 63028, 46284, 34918, 29442, 27197, 23353, 39549, 34263, 44710]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executor.submit\n",
    "\n",
    "`submit` starts an execution in a separate thread or process and immediately returns a `Future` object that points back to the result. Until the function completes, the future is pending. We get the result of a task with `.result()`, which blocks until the computation is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.98 ms, sys: 13.4 ms, total: 19.3 ms\n",
      "Wall time: 17.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from time import sleep\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor() \n",
    "\n",
    "def slowfunc(x,y,delay=1):\n",
    "    sleep(delay)\n",
    "    return(x+y)\n",
    "\n",
    "future = e.submit(slowfunc,1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x104bfb080 state=finished returned int>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.67 ms, sys: 3.31 ms, total: 11 ms\n",
      "Wall time: 3.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "futures = [e.submit(slowfunc,1,2, delay=1) for _ in range(10)]\n",
    "results = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joblib\n",
    "\n",
    "http://pythonhosted.org/joblib/\n",
    "\n",
    "Running Python functions as pipeline jobs. The *vision is to provide tools to easily achieve better performance and reproducibility when working with long running jobs.* Specifically meant to work well with large data (ie. numpy arrays)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - **Avoid computing twice the same thing**: code is rerun over an over, for instance when prototyping computational-heavy jobs (as in scientific development), but hand-crafted solution to alleviate this issue is error-prone and often leads to unreproducible results\n",
    "  - **Persist to disk transparently**: persisting in an efficient way arbitrary objects containing large data is hard. Using joblib’s caching mechanism avoids hand-written persistence and implicitly links the file on disk to the execution context of the original Python object. As a result, joblib’s persistence is good for resuming an application status or computational job, eg after a crash.\n",
    "\n",
    "Joblib strives to address these problems while leaving your code and your flow control as unmodified as possible (no framework, no new paradigms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!conda install joblib -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "[sqrt(i ** 2) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Helpers\n",
    "\n",
    "Joblib provides a simple helper class to write parallel for loops using multiprocessing. The core idea is to write the code to be executed as a generator expression, and convert it to parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Parallel uses the Python multiprocessing module to fork separate Python worker processes to execute tasks concurrently on separate CPUs. This is a reasonable default for generic Python programs but it induces some overhead as the input and output data need to be serialized in a queue for communication with the worker processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=2,backend=\"threading\") \\\n",
    "  (delayed(sqrt)(i ** 2) for i in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "Parallel(n_jobs=10,verbose=5) \\\n",
    "  (delayed(time.sleep)(1) for _ in range(10))\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On demand recomputing: the `Memory` class\n",
    "\n",
    "Caching long running results so it can be reused. Let's try to cache to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "memory = Memory(cachedir=\"/tmp/\", verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def f(x):\n",
    "    print('Running f(%s)' % x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -lat /tmp/joblib/__main__--Users-jbloom-Classes-python-seminar-DataFiles_and_Notebooks-08_Parallelism-__ipython-input__/f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "memory = Memory(cachedir=\"/tmp/\",verbose=1,mmap_mode=\"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def g(x,blah=True):\n",
    "    print('Running g(%s)' % x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(g(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(g(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(g(1,blah=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache(ignore=['blah'])\n",
    "def h(x,blah=True):\n",
    "    print('Running h(%s)' % x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(h(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(h(1,blah=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: joblib also gives (for persistence) `joblib.dump()` and `joblib.load()` provide a replacement for pickle to work efficiently on Python objects containing large data, in particular large numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
